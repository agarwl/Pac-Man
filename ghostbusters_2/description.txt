Q1 and Q2) 

 In getBeliefDistribution(), I just converted the particle list into a Counter and then normalized the counter.
 In intializeParticles(), I evenly distribute legal ghost positions into particles.

 In observe(),
 I first calculate the beliefDistribution using current particles.
 Then I update the distribution as done in previous lab and then sample from the new belief distribution to get the new particles.
    
    In the case when noisyDistance is not None, I update our beliefs by calculating the posterior
    distribution for beliefs by using our prior beliefs i.e. posterior = prior * likelihood where 
    our new belief of ghost being present in a position p is given by prior belief of ghost being present in position p multiplied by the probability of observing the nosiyDistance given that the ghost is in the position p.
    i.e newBelief[pos] = belief[pos] * P(noisyDistance | pos) (in code , it's trueDistance calculated using pos)

    If noisyDistance is None, it means the ghost has been caputured at a position 'p' given by self.JailPosition() and our beleifs are updated in such a way that I assign probability 1 to position 'p' and probability 0 for other self.legalPositions().

Similarly in time elapse(), I get the new belief distribution by propagating the old beliefs obtained by get belief distributin and then sample from the new distribution to get the particles.


Q3)
 In getBeliefDistribution(), I just converted the particle list into a Counter and then normalized the counter.
 In intializeParticles(), I calculated K cartesian product of legal positions of ghosts where K = number of ghosts. Then, I evenly distribute these positions into particles.

 In observeState(), I first get the current belief distribution and using it
 If noisyDistances[i] != None,
 	for each particle p:
 		new_belief[p] is intialized to belief[p]
 		for each ghost g:
 			if g is not captured:
 				new_belief[p] is updated by multiplying by (prob of g in position given by p given by emission model)

After getting new positions of the particle, for the captured ghosts put that ghost in jail position in the new Paritcle positions using getParticleWithGhostInJail.

Q4)

In this, each ghost should draw a new position conditioned on the positions of all the ghosts at the previous time step. This is done using getting the old positions of the ghosts and using the getPositionDistributionForGhost on a gamestate where ghosts are placed on the old_positions.
This gives a prob dist over the all possible new positions for that particular ghost and then I sample from this distrubution to get the new Position.

There is a fast convergence in test case 3 as I are using both elapseTime and observe implementations IN test case 3 while in the test case 1 I are using only the elapseTime implmented in Q4. Since I are using more information (more evidence) in test case 3 than 1, I observe faster convergence.